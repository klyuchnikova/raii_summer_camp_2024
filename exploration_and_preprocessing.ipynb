{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# for hierarchical clusterization\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from scipy.spatial.distance import  pdist\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# system\n",
    "from datetime import datetime\n",
    "import os\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "acc50df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5b9754e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_tkn</th>\n",
       "      <th>flat_tkn</th>\n",
       "      <th>payment_period</th>\n",
       "      <th>income</th>\n",
       "      <th>debt</th>\n",
       "      <th>raised</th>\n",
       "      <th>volume_cold</th>\n",
       "      <th>volume_hot</th>\n",
       "      <th>volume_electr</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23170</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2073.48</td>\n",
       "      <td>2046.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.33</td>\n",
       "      <td>6.91416</td>\n",
       "      <td>199.50</td>\n",
       "      <td>2_23170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23170</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>1525.44</td>\n",
       "      <td>2484.21</td>\n",
       "      <td>2404.08</td>\n",
       "      <td>5.19</td>\n",
       "      <td>4.22532</td>\n",
       "      <td>186.00</td>\n",
       "      <td>2_23170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23170</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>1762.49</td>\n",
       "      <td>2337.36</td>\n",
       "      <td>1672.29</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.82284</td>\n",
       "      <td>227.50</td>\n",
       "      <td>2_23170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>23170</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>1868.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4099.85</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13227</td>\n",
       "      <td>242.03</td>\n",
       "      <td>2_23170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23170</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2682.54</td>\n",
       "      <td>1933.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.64</td>\n",
       "      <td>6.91416</td>\n",
       "      <td>362.00</td>\n",
       "      <td>2_23170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_tkn  flat_tkn payment_period   income     debt   raised  volume_cold  \\\n",
       "0          2     23170     2023-01-01  2073.48  2046.36     0.00         5.33   \n",
       "1          2     23170     2023-03-01  1525.44  2484.21  2404.08         5.19   \n",
       "2          2     23170     2023-04-01  1762.49  2337.36  1672.29         5.00   \n",
       "3          2     23170     2023-05-01  1868.41     0.00  4099.85         5.08   \n",
       "4          2     23170     2023-07-01  2682.54  1933.29     0.00         8.64   \n",
       "\n",
       "   volume_hot  volume_electr  user_id  \n",
       "0     6.91416         199.50  2_23170  \n",
       "1     4.22532         186.00  2_23170  \n",
       "2     4.82284         227.50  2_23170  \n",
       "3     5.13227         242.03  2_23170  \n",
       "4     6.91416         362.00  2_23170  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data//raai_school_2024.csv\", sep = \";\")\n",
    "data[\"payment_period\"] = pd.to_datetime(data[\"payment_period\"])\n",
    "data['user_id'] = data['house_tkn'].astype(str) + '_' + data['flat_tkn'].astype(str)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5bcaabc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3206079, 10)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b03d94",
   "metadata": {},
   "source": [
    "## Descriptional analysis\n",
    "\n",
    "На что надо обратить внимание\n",
    "\n",
    "1. Как можно заметить внизу в данных есть заметные выбросы. Но они легко отбрасываются при помощи 5% перцентиля.\n",
    "2. В данных $volume$ есть пробелы заполенные NaN. Их не получится просто отбросить учитывая что они занимают почти половину строк. Факт: было подтверждено что у многих вместо горячей воды стоят какие-то собственные приспособление так что за горячую воду они не платят. Осталось догадаться, понять есть ли люди без элекричества или дом просто пустует.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8672a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['income', 'debt', 'raised']\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 6))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    lower_bound = np.percentile(data[feature].dropna(), 5)\n",
    "    upper_bound = np.percentile(data[feature].dropna(), 95)\n",
    "    filtered_data = data[feature][(data[feature] >= lower_bound) & (data[feature] <= upper_bound)].dropna()\n",
    "    axes[i].hist(filtered_data, bins=20, alpha=0.5)  # Apply log transformation\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc06d22",
   "metadata": {},
   "source": [
    "### Searching anomalies with scatter plots and basic deduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'volume_cold', y = 'volume_hot', data = data)\n",
    "plt.title('Points of cold, hot volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830af183",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Meanwhile median for cold water: {data.volume_cold.median()}, hot water: {data.volume_hot.median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d037f",
   "metadata": {},
   "source": [
    "### Мини исследование отсутствующих значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['volume_cold_na'] = data.volume_cold.isna()\n",
    "data['volume_hot_na'] = data.volume_hot.isna()\n",
    "data['volume_electr_na'] = data.volume_electr.isna()\n",
    "\n",
    "counts = pd.DataFrame({\n",
    "    'volume_cold_na': [data['volume_cold_na'].sum(), \n",
    "                       data[['volume_cold_na', 'volume_hot_na']].all(axis=1).sum(),\n",
    "                       data[\n",
    "                           ['volume_cold_na', 'volume_electr_na']].all(axis=1).sum()],\n",
    "    'volume_hot_na': [data[\n",
    "                           ['volume_cold_na', 'volume_hot_na']].all(axis=1).sum(),\n",
    "                       data['volume_hot_na'].sum(),\n",
    "                       data[['volume_hot_na', 'volume_electr_na']].all(axis=1).sum()],\n",
    "    'volume_electr_na': [data[['volume_cold_na', 'volume_electr_na']].all(axis=1).sum(),\n",
    "                       data[['volume_hot_na', 'volume_electr_na']].all(axis=1).sum(),\n",
    "                       data['volume_electr_na'].sum()]\n",
    "}, index=['volume_cold_na', 'volume_hot_na', 'volume_electr_na'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(counts, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Missing Values')\n",
    "plt.ylabel('Missing Values')\n",
    "plt.title('Intersection of Missing Values in School Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_no_hot_water = data['volume_hot_na'] & (1 - data['volume_cold_na'])\n",
    "cold_and_hot_water = (1 - data['volume_hot_na']) & (1 - data['volume_cold_na'])\n",
    "no_cold_no_hot_water = data['volume_hot_na'] & data['volume_cold_na']\n",
    "\n",
    "features = ['income', 'raised', 'volume_cold', 'volume_electr']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(8, 20))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    lower_bound = np.percentile(data[feature].dropna(), 5)\n",
    "    upper_bound = np.percentile(data[feature].dropna(), 95)\n",
    "    filtered_indices = (data[feature] >= lower_bound) & (data[feature] <= upper_bound)\n",
    "\n",
    "    filtered_cold_no_hot_water = data[feature][cold_no_hot_water & filtered_indices].dropna()\n",
    "    filtered_cold_and_hot_water = data[feature][cold_and_hot_water & filtered_indices].dropna()\n",
    "    filtered_no_cold_no_hot_water = data[feature][no_cold_no_hot_water & filtered_indices].dropna()\n",
    "\n",
    "    axes[i].hist(np.log(filtered_cold_no_hot_water + 1), alpha=0.5, label='Cold Only', bins=20)\n",
    "    axes[i].hist(np.log(filtered_cold_and_hot_water + 1), alpha=0.5, label='Cold & Hot', bins=20)\n",
    "    axes[i].hist(np.log(filtered_no_cold_no_hot_water + 1), alpha=0.5, label='No Cold & No Hot', bins=20)\n",
    "    \n",
    "    axes[i].set_xlabel(\"Log \" + feature)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.title(\"Difference between flats with or without hot water\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d764aeb",
   "metadata": {},
   "source": [
    "### Исследование по электричеству\n",
    "\n",
    "Выводы:\n",
    "- если электричества нет то совершенно не факт что нет показателей воды.\n",
    "- в 37% случаев есть показания воды хотя нет электрчества\n",
    "- если есть показания горячей воды то почти наверное есть холодная вода, хотя один процент несколько подозрителен. Были замечены некоторые дома с подозрительным количеством жителей у которых только горячая вода, хотя большая часть все же распределена по небольшим группам\n",
    "- внизу я еще пыталась понять как выглядят те пользователи без холодной воды и стало понятно что большая часть - индивидуальные случаи максимум с парой показаний, вероятно у них просто что-то сломалось. С другой стороны есть дома с массовым отсутствием воды (типа 50 жителей без холодной воды судя по всему по 9 месяцев). Странный дом, а именно 144191 имеет аж 124 жителя которые живут без холодной воды до 7 месяцев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7903054",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percent of houses with hot & cold water:\", sum((1 - data['volume_hot_na']) & (1 - data['volume_cold_na'])) / data.shape[0] * 100)\n",
    "print(\"Percent of houses with only cold water:\", sum(data['volume_hot_na'] & (1 - data['volume_cold_na'])) / data.shape[0] * 100)\n",
    "print(\"Percent of houses with only hot water:\", sum(data['volume_cold_na'] & (1 - data['volume_hot_na'])) / data.shape[0] * 100)\n",
    "print(\"Percent of houses with no hot & no cold water:\", sum((1 - data['volume_hot_na']) & (1 - data['volume_cold_na'])) / data.shape[0] * 100)\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Percent of houses with no electricity yet cold water:\", sum(data['volume_electr_na'] & (1 - data['volume_cold_na'])) / data.shape[0] * 100)\n",
    "print(\"Percent of houses with no electricity yet hot water:\", sum(data['volume_electr_na'] & (1 - data['volume_hot_na'])) / data.shape[0] * 100)\n",
    "print(\"Percent of houses with no electricity yet cold & hot water:\", sum(data['volume_electr_na'] & (1 - data['volume_cold_na']) & (1 - data['volume_hot_na'])) / data.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1686883",
   "metadata": {},
   "source": [
    "### Выделение пользователей у которых нет горячей воды / отключение выборочное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month_of_admission'] = data['payment_period'].map(lambda dt: dt.strftime('%Y-%m'))\n",
    "data.groupby('month_of_admission')[\"volume_hot_na\"].sum().to_frame(\"count\").reset_index().plot(kind='bar', x='month_of_admission', y='count', title = \"Distribution of no-hot-water entries between months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average number months of payment: {grouped.size().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values('payment_period')\n",
    "grouped = data.groupby('user_id')\n",
    "\n",
    "def check_missing_months(user_data):\n",
    "    # Sort by 'month_of_admission'\n",
    "    user_data = user_data.sort_values('payment_period')\n",
    "    # user_data['payment_period'] = pd.to_datetime(user_data['payment_period'])\n",
    "    \n",
    "    first_month = user_data['payment_period'].min()\n",
    "    last_month = user_data['payment_period'].max()\n",
    "    expected_months = pd.date_range(first_month, last_month, freq='MS', inclusive=\"both\")\n",
    "\n",
    "    # Find missing months\n",
    "    missing_months = expected_months[~expected_months.isin(user_data['payment_period'])]\n",
    "    exclude_months = pd.to_datetime([\"2023-10-01\", \"2023-12-01\"])\n",
    "    missing_months = missing_months[~missing_months.isin(exclude_months)]\n",
    "    return missing_months\n",
    "\n",
    "number_skips = 0\n",
    "for user_id, user_data in grouped:\n",
    "    i += 1\n",
    "    missing_months = check_missing_months(user_data)\n",
    "    if missing_months is not None and not missing_months.empty:\n",
    "        if number_skips < 100:\n",
    "            print(f\"User {user_id} has missing months: {missing_months.strftime('%Y-%m').tolist()}\")\n",
    "        number_skips += 1\n",
    "print(number_skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09631831",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[grouped[\"user_id\"] == \"100005_263170\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby('user_id')\n",
    "\n",
    "def check_missing_months(user_data):\n",
    "    # Sort by 'month_of_admission'\n",
    "    user_data = user_data.sort_values('month_of_admission')\n",
    "    user_data['month_of_admission'] = pd.to_datetime(user_data['month_of_admission'])\n",
    "    \n",
    "    first_month = user_data['month_of_admission'].min()\n",
    "    last_month = user_data['month_of_admission'].max()\n",
    "    expected_months = pd.date_range(first_month, last_month, freq='M')\n",
    "\n",
    "    # Find missing months\n",
    "    missing_months = expected_months[~expected_months.isin(user_data['month_of_admission'])]\n",
    "    return missing_months\n",
    "\n",
    "for user_id, user_data in grouped:\n",
    "    missing_months = check_missing_months(user_data)\n",
    "    if not missing_months.empty:\n",
    "        print(f\"User {user_id} has missing months: {missing_months.strftime('%Y-%m').tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a436642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan how to devide users into groups with \n",
    "\n",
    "grouped = data.groupby('user_id')\n",
    "users_with_no grouped[\"volume_hot_na\"].sum().astype(int).reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee53cc",
   "metadata": {},
   "source": [
    "### Отдельное исследование людей с горячей водой но не холодной :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_guys = data[data['volume_cold_na'] & (1 - data['volume_hot_na'])] # hot & no cold\n",
    "weird_guys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9927ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of houses with citizens who got only hot water yet no cold {len(weird_guys.house_tkn.unique())}, average entries per house {weird_guys.shape[0] / len(weird_guys.house_tkn.unique())}\\nMeanwhile there're average {data.shape[0] / len(data.house_tkn.unique())} entries per house in all data\")\n",
    "\n",
    "print(f\"Number of unique citizens who got only hot water yet no cold {len(weird_guys.user_id.unique())}, average entries per user {weird_guys.shape[0] / len(weird_guys.user_id.unique())}\\nMeanwhile there're average {data.shape[0] / len(data.user_id.unique())} entries per user in all data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c323fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(weird_guys.house_tkn.value_counts()), bins = 10)\n",
    "plt.title(\"Logged number entries with hot & no cold water per house\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_guys.groupby(\"user_id\").size().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_guys.groupby(\"house_tkn\").size().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ebf266",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cursed house:\")\n",
    "print(\"Number cursed flats in the cursed house:\", weird_guys[weird_guys[\"house_tkn\"] == 144191][\"user_id\"].nunique())\n",
    "print(\"Number cursed entries for dwellers of the cursed house:\", weird_guys[weird_guys[\"house_tkn\"] == 144191][\"user_id\"].value_counts().mean())\n",
    "print(\"Number super cursed dwellers of the house:\", sum(weird_guys[weird_guys[\"house_tkn\"] == 144191][\"user_id\"].value_counts() == 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a294753",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(weird_guys.groupby(\"house_tkn\")[\"user_id\"].nunique(), bins = 20)\n",
    "plt.title(\"Number users with hot & no cold water per house\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_guys.groupby(\"house_tkn\")[\"user_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_guys.house_tkn.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aca8ab",
   "metadata": {},
   "source": [
    "## Распределение по месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df545ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month_of_admission'] = data['payment_period'].map(lambda dt: dt.strftime('%Y-%m'))\n",
    "data.groupby('month_of_admission').size().to_frame(\"count\").reset_index().plot(kind='bar', x='month_of_admission', y='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08752885",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- удаление двух месяцев у которых мало записей\n",
    "- one-hot encoding месяцев\n",
    "- выделение конкретных **домов** с аномально маленькими/большими значениями по каждому из столбцов\n",
    "- EIF, возможно другие методы если он окажется неадекватным\n",
    "\n",
    "-> Результатом является data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38afc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting negative numbers from volumes\n",
    "ensure_positive_features = ['income', 'raised', 'volume_cold', 'volume_hot', 'volume_electr']\n",
    "for feature in ensure_positive_features:\n",
    "    if sum(data[feature] < 0) != 0:\n",
    "        print(f\"Feature {feature} has unexpected negative values: {sum(data[feature] < 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc91e4e",
   "metadata": {},
   "source": [
    "### удаление двух месяцев у которых мало записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data[(data[\"month_of_admission\"] != 10) & (data[\"month_of_admission\"] != 12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2181f0ae",
   "metadata": {},
   "source": [
    "### one-hot encoding месяцев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATASHA's code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc5b46",
   "metadata": {},
   "source": [
    "### выделение конкретных **домов** с аномально маленькими/большими значениями по каждому из столбцов\n",
    "- Наташа\n",
    "- ОБЯЗАТЕЛЬНО сделай чистку месяцев до этого.\n",
    "Удобно просто строить перцептили с pandas - посмотри как я выше это делала\n",
    "\n",
    "- Идеи: чуваки которые не отправляют данные и не платят (у них капает за электроэнергию). Чуваки которые тратят много ровно по одному параметру. Чуваки которые тратят много по всем параметрам (а-ля многодетная семья) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATASHA's code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb15769",
   "metadata": {},
   "source": [
    "### Artificial cutoff of the anomaly values\n",
    "\n",
    "- for each volume take a percentile, but do not exclude NaN or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['income', 'debt', 'raised',\n",
    "       'volume_cold', 'volume_hot', 'volume_electr']\n",
    "\n",
    "for feature in numeric_features:\n",
    "    threshold = data_numeric[feature].quantile(0.95)\n",
    "    data_filtered[feature] = data_filtered[feature].clip(upper=threshold)\n",
    "\n",
    "for feature in ['income', 'debt', 'raised']:\n",
    "    threshold = data_numeric[feature].quantile(0.05)\n",
    "    data_filtered[feature] = data_filtered[feature].clip(lower=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b1c78",
   "metadata": {},
   "source": [
    "### Filling NaN values\n",
    "1. Нахождение людей у которых просто нет горячей воды, заполнение таких значениями -1.\n",
    "2. Отрицательные значения volume временно заполняем 0\n",
    "3. Всех остальных имеет смысл заполнть медианой так как мы работаем на уровне записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered['month_of_admission'] = data_filtered['payment_period'].map(lambda dt: dt.month)\n",
    "numeric_features = ['income', 'debt', 'raised','volume_cold', 'volume_hot', 'volume_electr']\n",
    "data_numeric = data_filtered[numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46b77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filling all those who have no hot water with -1\n",
    "user_ids_who_have_no_hot = data.groupby(\"user_id\")[\"volume_hot_na\"].agg(lambda x: x.any())\n",
    "users_with_no_hot = data[data[\"user_id\"].isin(user_ids_who_have_no_hot[user_ids_who_have_no_hot].index)]\n",
    "users_with_no_hot[\"volume_hot\"] = users_with_no_hot[\"volume_hot\"].fillna(0)\n",
    "\n",
    "data_numeric = pd.concat([users_with_no_hot, data_numeric[~data[\"user_id\"].isin(users_with_no_hot[\"user_id\"])]])\n",
    "data_numeric = data_numeric[numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7688fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Entries with no hot water: {users_with_no_hot.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470491b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data_numeric.shape[0] == data_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79109f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling negative values with 0 (hot water as I previouslt overlooked didn't have any so we don't wanna clear previous result)\n",
    "\n",
    "data_numeric[\"volume_cold\"] = data_numeric[\"volume_cold\"].clip(lower=0)\n",
    "data_numeric[\"volume_electr\"] = data_numeric[\"volume_electr\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c718533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all the left NaNs with median\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "data_numeric_scaled = scaler.fit_transform(imputer.fit_transform(data_numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting index (WARNING! that would make index inconsistent with original data)\n",
    "\n",
    "data_numeric = data_numeric.reset_index(drop=True)\n",
    "data_filtered = data_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551be50e",
   "metadata": {},
   "source": [
    "### EIF for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d137c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Isolation forest from sklearn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "n_trees_values = [1, 5, 10, 50]\n",
    "max_samples_values = [0.33, 0.5, 0.7] \n",
    "contamination = 0.01\n",
    "\n",
    "scores = []\n",
    "\n",
    "subset_size = 0.1 \n",
    "subset_indices = np.random.choice(data_numeric_scaled.shape[0], int(subset_size * data_numeric_scaled.shape[0]), replace=False)\n",
    "data_subset = data_numeric_scaled[subset_indices]\n",
    "\n",
    "for n_trees in n_trees_values:\n",
    "    scores_ = []\n",
    "    for max_samples in max_samples_values:\n",
    "        print(f\"Processing n_trees = {n_trees}, max_samples = {max_samples}\")\n",
    "        eif = IsolationForest(n_estimators=n_trees, max_samples=max_samples, contamination=contamination)  # Use max_samples\n",
    "        eif.fit(data_subset)\n",
    "    \n",
    "        anomaly_scores = eif.decision_function(data_subset)\n",
    "        \n",
    "        score = np.mean(anomaly_scores)\n",
    "        scores_.append(score)\n",
    "\n",
    "    scores.append(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56cc00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "for i, n_trees in enumerate(n_trees_values):\n",
    "    plt.plot(max_samples_values, scores[i], label=f'n_trees {n_trees}')\n",
    "plt.xlabel('max_samples')\n",
    "plt.ylabel('Anomaly score')\n",
    "plt.title(\"Sklearn IsolationForest on 10% of data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b90efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eif = IsolationForest(n_estimators=10, max_samples=0.7, contamination=0.01)\n",
    "eif.fit(data_subset)\n",
    "\n",
    "subset_size = 1000\n",
    "subset_indices = np.random.choice(data_numeric_scaled.shape[0], subset_size, replace=False)\n",
    "data_subset_2 = data_numeric_scaled[subset_indices]\n",
    "\n",
    "original_subset = data_numeric.iloc[subset_indices].copy()\n",
    "original_subset[\"anomaly\"] = eif.predict(data_subset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['income', 'debt', 'raised','volume_cold', 'volume_hot', 'volume_electr']\n",
    "\n",
    "fig, axes = plt.subplots(len(features), len(features), figsize=(30, 28))\n",
    "\n",
    "for i, feature1 in enumerate(features):\n",
    "    for j, feature2 in enumerate(features):\n",
    "        if i == j:\n",
    "            axes[i, j].axis(\"off\")\n",
    "        else:\n",
    "            axes[i, j].scatter(\n",
    "                original_subset[feature1][original_subset[\"anomaly\"] == 1],\n",
    "                original_subset[feature2][original_subset[\"anomaly\"] == 1],\n",
    "                color=\"blue\",\n",
    "                label=\"Normal\",\n",
    "            )\n",
    "\n",
    "            # Scatter plot for anomalies\n",
    "            axes[i, j].scatter(\n",
    "                original_subset[feature1][original_subset[\"anomaly\"] == -1],\n",
    "                original_subset[feature2][original_subset[\"anomaly\"] == -1],\n",
    "                color=\"red\",\n",
    "                label=\"Anomaly\",\n",
    "            )\n",
    "\n",
    "            axes[i, j].set_xlabel(feature1)\n",
    "            axes[i, j].set_ylabel(feature2)\n",
    "            axes[i, j].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eif = IsolationForest(n_estimators=10, max_samples=0.7, contamination=0.01)\n",
    "anomaly_predictions = eif.fit_predict(data_numeric_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_indices = np.where(anomaly_predictions == -1)[0]\n",
    "\n",
    "subset_size = 1000\n",
    "subset_indices = np.random.choice(anomaly_indices, subset_size, replace=True)\n",
    "original_subset = data_numeric.iloc[subset_indices].copy()\n",
    "original_subset[\"anomaly\"] = anomaly_predictions[subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0924c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_indices = np.where(anomaly_predictions == 1)[0]\n",
    "data_filtered.iloc[normal_indices].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['income', 'debt', 'raised','volume_cold', 'volume_hot', 'volume_electr']\n",
    "fig, axes = plt.subplots(len(features), len(features), figsize=(30, 28))\n",
    "\n",
    "for i, feature1 in enumerate(features):\n",
    "    for j, feature2 in enumerate(features):\n",
    "        if i == j:\n",
    "            axes[i, j].axis(\"off\")\n",
    "        else:\n",
    "            axes[i, j].scatter(\n",
    "                original_subset[feature1][original_subset[\"anomaly\"] == -1],\n",
    "                original_subset[feature2][original_subset[\"anomaly\"] == -1],\n",
    "                color=\"red\",\n",
    "                label=\"Anomaly\",\n",
    "            )\n",
    "\n",
    "            axes[i, j].set_xlabel(feature1)\n",
    "            axes[i, j].set_ylabel(feature2)\n",
    "            axes[i, j].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"IF left {len(normal_indices)} normal, while {len(anomaly_indices)} are anomalies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a679a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving normal data that was filtered\n",
    "data_filtered.iloc[normal_indices].to_csv(\"filtered_unnormalized_data.csv\", sep=\";\", index=False)\n",
    "\n",
    "# Saving scaled data that has no NaN\n",
    "replace_columns = ['income', 'debt', 'raised', 'volume_cold', 'volume_hot', 'volume_electr']\n",
    "data_numeric_df = pd.DataFrame(data_numeric_scaled, columns=replace_columns)\n",
    "data_filtered[replace_columns] = data_numeric_df\n",
    "data_filtered.iloc[normal_indices].to_csv(\"filtered_scaled_data.csv\", sep=\";\", index=False)\n",
    "\n",
    "# Saving original data with anomaly tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0c67d661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_tkn</th>\n",
       "      <th>flat_tkn</th>\n",
       "      <th>payment_period</th>\n",
       "      <th>income</th>\n",
       "      <th>debt</th>\n",
       "      <th>raised</th>\n",
       "      <th>volume_cold</th>\n",
       "      <th>volume_hot</th>\n",
       "      <th>volume_electr</th>\n",
       "      <th>month_of_admission</th>\n",
       "      <th>volume_cold_na</th>\n",
       "      <th>volume_hot_na</th>\n",
       "      <th>volume_electr_na</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23170</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.187621</td>\n",
       "      <td>-0.146264</td>\n",
       "      <td>-0.145109</td>\n",
       "      <td>0.470157</td>\n",
       "      <td>0.791438</td>\n",
       "      <td>-0.039733</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2_23170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34737</td>\n",
       "      <td>208775</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.466695</td>\n",
       "      <td>-0.146041</td>\n",
       "      <td>-0.086698</td>\n",
       "      <td>-0.339071</td>\n",
       "      <td>0.322358</td>\n",
       "      <td>-0.039733</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>34737_208775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15899</td>\n",
       "      <td>163622</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.612532</td>\n",
       "      <td>-0.146041</td>\n",
       "      <td>-0.230077</td>\n",
       "      <td>-0.274897</td>\n",
       "      <td>-0.146721</td>\n",
       "      <td>-0.039733</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>15899_163622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94073</td>\n",
       "      <td>454760</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.798176</td>\n",
       "      <td>-0.146041</td>\n",
       "      <td>-0.485190</td>\n",
       "      <td>-0.210724</td>\n",
       "      <td>-0.615800</td>\n",
       "      <td>-0.039733</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>94073_454760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15899</td>\n",
       "      <td>163621</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.892711</td>\n",
       "      <td>-0.146041</td>\n",
       "      <td>-0.740313</td>\n",
       "      <td>-0.403244</td>\n",
       "      <td>-0.615800</td>\n",
       "      <td>-0.039733</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>15899_163621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_tkn  flat_tkn payment_period    income      debt    raised  \\\n",
       "0          2     23170     2023-01-01  0.187621 -0.146264 -0.145109   \n",
       "1      34737    208775     2023-01-01 -0.466695 -0.146041 -0.086698   \n",
       "2      15899    163622     2023-01-01 -0.612532 -0.146041 -0.230077   \n",
       "3      94073    454760     2023-01-01 -0.798176 -0.146041 -0.485190   \n",
       "4      15899    163621     2023-01-01 -0.892711 -0.146041 -0.740313   \n",
       "\n",
       "   volume_cold  volume_hot  volume_electr  month_of_admission  volume_cold_na  \\\n",
       "0     0.470157    0.791438      -0.039733                   1           False   \n",
       "1    -0.339071    0.322358      -0.039733                   1           False   \n",
       "2    -0.274897   -0.146721      -0.039733                   1           False   \n",
       "3    -0.210724   -0.615800      -0.039733                   1           False   \n",
       "4    -0.403244   -0.615800      -0.039733                   1           False   \n",
       "\n",
       "   volume_hot_na  volume_electr_na       user_id  \n",
       "0          False             False       2_23170  \n",
       "1          False              True  34737_208775  \n",
       "2          False              True  15899_163622  \n",
       "3          False              True  94073_454760  \n",
       "4          False              True  15899_163621  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered[\"is_anomaly\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "81a32947",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered[\"is_anomaly\"] = (anomaly_predictions == -1).astype(int)\n",
    "\n",
    "merged_data = pd.merge(\n",
    "    data,\n",
    "    data_filtered[[\"house_tkn\", \"flat_tkn\", \"payment_period\", \"is_anomaly\"]],\n",
    "    on=[\"house_tkn\", \"flat_tkn\", \"payment_period\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "data[\"is_anomaly\"] = merged_data[\"is_anomaly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "29186eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"original_data_with_anomaly_column.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6d393",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "number_features = ['income', 'debt', 'raised','volume_cold', 'volume_hot', 'volume_electr']\n",
    "data_with_real_numeric = data[number_features].dropna() \n",
    "data_with_real_numeric = (data_with_real_numeric-data_with_real_numeric.mean())/data_with_real_numeric.std()\n",
    "pearson = data_with_real_numeric.corr(method = 'pearson')\n",
    "sns.heatmap(pearson, annot = True, fmt = \".3f\")\n",
    "plt.title('Pearson correlation of numerical data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d723a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "number_features = ['income', 'debt', 'raised','volume_cold', 'volume_hot', 'volume_electr']\n",
    "data_with_real_numeric = data[number_features].dropna() \n",
    "data_with_real_numeric = (data_with_real_numeric-data_with_real_numeric.mean())/data_with_real_numeric.std()\n",
    "spearman = data_with_real_numeric.corr(method = 'spearman')\n",
    "sns.heatmap(spearman, annot = True, fmt = \".3f\")\n",
    "plt.title('Spearman correlation of numerical data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dec043",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "number_features = ['income', 'debt', 'raised','volume_cold', 'volume_hot', 'volume_electr']\n",
    "data_with_real_numeric = data[number_features]\n",
    "data_with_real_numeric = (data_with_real_numeric-data_with_real_numeric.mean())/data_with_real_numeric.std()\n",
    "spearman = data_with_real_numeric.corr(method = 'spearman')\n",
    "sns.heatmap(spearman, annot = True, fmt = \".3f\")\n",
    "plt.title('Spearman correlation of numerical data including NaNs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fa630",
   "metadata": {},
   "source": [
    "### Correlation on normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72332d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbfac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered_normal_scaled = pd.read_csv(\"data//filtered_scaled_data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "number_features = ['income', 'debt', 'raised','volume_cold', 'volume_hot', 'volume_electr']\n",
    "data_with_real_numeric = data_filtered_normal_scaled.dropna() \n",
    "data_with_real_numeric = (data_with_real_numeric-data_with_real_numeric.mean())/data_with_real_numeric.std()\n",
    "pearson = data_with_real_numeric.corr(method = 'pearson')\n",
    "sns.heatmap(pearson, annot = True, fmt = \".3f\")\n",
    "plt.title('Pearson correlation of numerical data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "number_features = ['income', 'debt', 'raised','volume_cold', 'volume_hot', 'volume_electr']\n",
    "data_with_real_numeric = data_filtered_normal_scaled.dropna() \n",
    "data_with_real_numeric = (data_with_real_numeric-data_with_real_numeric.mean())/data_with_real_numeric.std()\n",
    "spearman = data_with_real_numeric.corr(method = 'spearman')\n",
    "sns.heatmap(spearman, annot = True, fmt = \".3f\")\n",
    "plt.title('Spearman correlation of numerical data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a846a8",
   "metadata": {},
   "source": [
    "# Кластеризация данных\n",
    "\n",
    "- если делать деревом решений то не должно возникать проблемы с NaN значениями\n",
    "- если делать стандартными методам сначала надо нормализовать и разделить данные на NaN и все остальные, либо выделять тех у кого только холодная вода с целью заставить им эту воду 0, а остальных кокнуть как аномалии вручную. Некоторые стандартные методы: K-Means, DBSCAN\n",
    "\n",
    "**До начала кластеризации** надо убрать дома и квартиры объединив их в $user\\_id$. Дальше надо подумать о том каие признаки можно дабвить в табличку (например максимум, минимум, среднее, отклонение, частота выплат). Также можно пытаться учесть отдельно\n",
    "1. летний период отключения горячей воды\n",
    "2. отсутствие горячей воды в доме\n",
    "3. периоды повышенного потребления воды, например столбца по типу +1 за зимний месяц, -1 за летний или вообще булевые (для K-means очевидно плохая идея)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user_id'] = data['house_tkn'].astype(str) + '_' + data['flat_tkn'].astype(str)\n",
    "\n",
    "grouped = data.groupby('user_id')\n",
    "user_features = grouped.agg({\n",
    "    'income': 'mean',\n",
    "    'debt': 'mean',\n",
    "    'raised': 'mean',\n",
    "    'volume_cold': ['mean', 'std'],\n",
    "    'volume_hot': ['mean', 'std'],\n",
    "    'volume_electr': ['mean', 'std'],\n",
    "    'payment_period': ['min', 'max', 'nunique'],\n",
    "})\n",
    "\n",
    "user_features.columns = ['_'.join(col) for col in user_features.columns]\n",
    "\n",
    "# 3. Extract Payment Pattern Features\n",
    "\n",
    "# Create a column for payment delay\n",
    "user_features['payment_delay'] = (user_features['payment_period_max'] - user_features['payment_period_min']).dt.days\n",
    "user_features['payment_delay'] /= user_features['payment_period_nunique']  # Average delay per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc496b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
